## install devtools package if it's not already
if (!requireNamespace("devtools", quietly = TRUE)) {
install.packages("devtools")
}
install.packages('mapproj')
library(mapproj)
## install dev version of rtweet from github
devtools::install_github("mkearney/rtweet")
completeFun <- function(data, desiredCols) {
completeVec <- complete.cases(data[, desiredCols])
return(data[completeVec, ])
}
latlong2state <- function(pointsDF) {
# Prepare SpatialPolygons object with one SpatialPolygon
# per state (plus DC, minus HI & AK)
states <- map('state', fill=TRUE, col="transparent", plot=FALSE)
IDs <- sapply(strsplit(states$names, ":"), function(x) x[1])
states_sp <- map2SpatialPolygons(states, IDs=IDs,
proj4string=CRS("+proj=longlat +datum=WGS84"))
# Convert pointsDF to a SpatialPoints object
pointsSP <- SpatialPoints(pointsDF,
proj4string=CRS("+proj=longlat +datum=WGS84"))
# Use 'over' to get _indices_ of the Polygons object containing each point
indices <- over(pointsSP, states_sp)
# Return the state names of the Polygons object containing each point
stateNames <- sapply(states_sp@polygons, function(x) x@ID)
stateNames[indices]
}
my_data <- read.table("C:/Users/yasha/Desktop/influenza.csv")
filter<-my_data[!duplicated(my_data$V2), ]
library(maps)
library(sf)
library(sp)
library(maptools)
## Get the states map, turn into sf object
testPoints <- data.frame(x=as.numeric(as.character(filter$V90)), y=as.numeric(as.character(filter$V89)))
st <- data.frame(latlong2state(testPoints))
st_c <- as.data.frame(table(unlist(st)))
shiny::runApp('~/Shiny_App')
runApp('~/Shiny_App')
runApp('~/Shiny_App')
library(staedata)
library(statedata)
library(fiftystater)
runApp('~/Shiny_App')
runApp('~/Shiny_App')
runApp('~/Shiny_App')
shiny::runApp('~/Shiny_App')
runApp('~/Shiny_App')
runApp('~/Shiny_App')
my_data <- read.table("C:/Users/yasha/Desktop/flu.csv")
my_data <- read.table("C:/Users/yasha/Desktop/flu.csv")
filter<-my_data[!duplicated(my_data$V2), ]
filter<-filter[!filter$V11,]
## Get the states map, turn into sf object
testPoints <- data.frame(x=as.numeric(as.character(filter$V90)), y=as.numeric(as.character(filter$V89)))
register_google(key = "AIzaSyAEjFBLbaOwtPHi1hXzdoqrwoq5oeNqYF4")
library(ggmap)
register_google(key = "AIzaSyAEjFBLbaOwtPHi1hXzdoqrwoq5oeNqYF4")
result <- do.call(rbind,
lapply(1:nrow(testPoints),
function(i)
revgeocode(as.numeric(
testPoints[i,1:2]), output = "address")))
write.csv(result, file = "C:/Users/yasha/Desktop/geo_flu.csv")
result<-read.csv("C:/Users/yasha/Desktop/geo_flu.csv")
result<-data.frame(result)
result$abr<-str_sub(result$V1, -13, -12)
result$state<-abbr2state(result$abr)
library(stringr)
library(openintro)
result$abr<-str_sub(result$V1, -13, -12)
result$state<-abbr2state(result$abr)
st_c <- as.data.frame(table(unlist(result$state)))
st_c$Var1 <- tolower(st_c$Var1)
my_data <- read.table("C:/Users/yasha/Desktop/influenza.csv")
filter<-my_data[!duplicated(my_data$V2), ]
filter<-filter[!filter$V11,]
## Get the states map, turn into sf object
testPoints <- data.frame(x=as.numeric(as.character(filter$V90)), y=as.numeric(as.character(filter$V89)))
register_google(key = "AIzaSyAEjFBLbaOwtPHi1hXzdoqrwoq5oeNqYF4")
result <- do.call(rbind,
lapply(1:nrow(testPoints),
function(i)
revgeocode(as.numeric(
testPoints[i,1:2]), output = "address")))
write.csv(result, file = "C:/Users/yasha/Desktop/geo_influenza.csv")
result<-read.csv("C:/Users/yasha/Desktop/geo_influenza.csv")
result<-data.frame(result)
result$abr<-str_sub(result$V1, -13, -12)
result$state<-abbr2state(result$abr)
st_c <- as.data.frame(table(unlist(result$state)))
st_c$Var1 <- tolower(st_c$Var1)
View(st_c)
runApp('~/Shiny_App')
install.packages("mapproj")
runApp('~/Shiny_App')
runApp('~/Shiny_App')
runApp('~/Shiny_App')
View(my_data)
View(result)
result<-read.csv("C:/Users/yasha/Desktop/geo_influenza.csv")
View(result)
result<-read.csv("C:/Users/yasha/Desktop/geo_flu.csv")
View(result)
runApp('~/Shiny_App')
runApp('~/Shiny_App')
runApp('~/Shiny_App')
View(st_c)
my_data <- read.table("C:/Users/yasha/Desktop/influenza.csv")
filter<-my_data[!duplicated(my_data$V2), ]
filter<-filter[!filter$V11,]
## plot state boundaries
par(mar = c(0, 0, 0, 0))
maps::map("state", lwd = .25)
## plot lat and lng points onto state map
with(filter, points(V90, V89, pch = 20, cex = .75, col = rgb(0, .3, .7, .75)))
library(urbnmapr)
library(usmap)
library(maptools)
library(openintro)
library(stringr)
## Get the states map, turn into sf object
testPoints <- data.frame(x=as.numeric(as.character(filter$V90)), y=as.numeric(as.character(filter$V89)))
register_google(key = "AIzaSyAEjFBLbaOwtPHi1hXzdoqrwoq5oeNqYF4")
result <- do.call(rbind,
lapply(1:nrow(testPoints),
function(i)
revgeocode(as.numeric(
testPoints[i,1:2]), output = "address")))
result<-read.csv("C:/Users/yasha/Desktop/geo_flu.csv")
result<-data.frame(result)
result$abr<-str_sub(result$V1, -13, -12)
result$state<-abbr2state(result$abr)
st_c <- as.data.frame(table(unlist(result$state)))
library(ggplot2)
library(maps)
map.df <- merge(statedata,st_c, by.x="state_name",by.y='Var1', all.x=T)
map.df <- map.df[order(map.df$order),]
plot_usmap(data = map.df, values = "Freq", lines = "black") +
scale_fill_gradientn(colours=c('green3','yellow','darkorange1','red','red3', 'darkred'),na.value="green3",name = "Activity_Level", label = scales::comma)+
theme(legend.position = "right")
plot_usmap(data = map.df, values = "Freq", lines = "black") +
scale_fill_gradientn(colours=c('green3','yellow','darkorange1','red','red3', 'darkred'),na.value="green3",name = "Activity_Level", label = scales::comma)+
theme(legend.position = "right")
map.df$fips <- map.df$state_fips
plot_usmap(data = map.df, values = "Freq", lines = "black") +
scale_fill_gradientn(colours=c('green3','yellow','darkorange1','red','red3', 'darkred'),na.value="green3",name = "Activity_Level", label = scales::comma)+
theme(legend.position = "right")
result<-read.csv("C:/Users/yasha/Desktop/geo.csv")
result<-data.frame(result)
result$abr<-str_sub(result$V1, -13, -12)
result$state<-abbr2state(result$abr)
st_c <- as.data.frame(table(unlist(result$state)))
library(ggplot2)
library(maps)
map.df <- merge(statedata,st_c, by.x="state_name",by.y='Var1', all.x=T)
map.df$fips <- map.df$state_fips
plot_usmap(data = map.df, values = "Freq", lines = "black") +
scale_fill_gradientn(colours=c('green3','yellow','darkorange1','red','red3', 'darkred'),na.value="green3",name = "Activity_Level", label = scales::comma)+
theme(legend.position = "right")
runApp('~/Shiny_App')
runApp('~/Shiny_App')
runApp('~/Shiny_App')
install.packages('urbnmapr')
install.packages("urbnmapr")
da <- result<-read.csv("pt.csv")
result<-read.csv("geo.csv")
da <- result<-read.csv("pt.csv")
da <- result<-read.csv("C:/Users/yasha/Documents/Shiny_App/pt.csv")
da <- result<-read.table("C:/Users/yasha/Documents/Shiny_App/pt.csv")
ta <- tail(da, 1000)
write.table(ta, file = "C:/Users/yasha/Documents/Shiny_App/tweet.csv")
## install devtools package if it's not already
if (!requireNamespace("devtools", quietly = TRUE)) {
install.packages("devtools")
}
## install mapproj package if it's not already
if (!requireNamespace("mapproj", quietly = TRUE)) {
install.packages('mapproj')
}
## install dev version of rtweet from github
devtools::install_github("mkearney/rtweet")
## Function to remove rows based on NA value in particular column
completeFun <- function(data, desiredCols) {
completeVec <- complete.cases(data[, desiredCols])
return(data[completeVec, ])
}
## load rtweet package and other package
library(rtweet)
library(mapproj)
## twitter credentials
create_token(
app = "my_twitter_research_app",
access_token = '158904066-8UrgRY8p66DicZ5leg64B3cbNGhlopbSDnX8In3B',
access_secret = 'SYNq5Ls98oD4VnGYZ39nqFm8YZjYvNrUptHNLVSM9PLqv',
consumer_key = 'CS6hB0QXIphgzC55W86QqP4EO',
consumer_secret = 'YkWolqp6TK8umMlkg980yVYXDePm8LTt8MYhmDaRexfmDJd9rB')
write.table(rf, file = "rt.csv", append= T, row.names=FALSE, col.names = FALSE)
## create lat/lng variables using all available tweet and profile geo-location data
rt <- lat_lng(rt)
## create lat/lng variables using all available tweet and profile geo-location data
rt<- data.frame(rt)
rt <- lat_lng(rt)
my_data <- read.table("influenza.csv")
## filtering based on duplicate tweet and retweet
filter<-my_data[!duplicated(my_data$V2), ]
filter<-filter[!filter$V11,]
## plot state boundaries
par(mar = c(0, 0, 0, 0))
maps::map("state", lwd = .25)
## plot lat and lng points onto state map
with(filter, points(V90, V89, pch = 20, cex = .75, col = rgb(0, .3, .7, .75)))
## load packages
library(urbnmapr)
library(usmap)
library(maptools)
library(openintro)
library(stringr)
## turning lat,long into states
testPoints <- data.frame(x=as.numeric(as.character(filter$V90)), y=as.numeric(as.character(filter$V89)))
## storing ststes information
result<-read.csv("geo.csv")
result<-data.frame(result)
result$abr<-str_sub(result$V1, -13, -12)
result$state<-abbr2state(result$abr)
st_c <- as.data.frame(table(unlist(result$state)))
library(ggplot2)
library(maps)
map.df <- merge(statedata,st_c, by.x="state_name",by.y='Var1', all.x=T)
map.df$fips <- map.df$state_fips
plot_usmap(data = map.df, values = "Freq", lines = "black") +
scale_fill_gradientn(colours=c('green3','yellow','darkorange1','red','red3', 'darkred'),na.value="green3",name = "Activity_Level", label = scales::comma)+
theme(legend.position = "right")
